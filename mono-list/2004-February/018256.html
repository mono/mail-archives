<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2//EN">
<HTML>
 <HEAD>
   <TITLE> [Mono-list] unicode trouble
   </TITLE>
   <LINK REL="Index" HREF="index.html" >
   <LINK REL="made" HREF="mailto:jonpryor%40vt.edu">
   <META NAME="robots" CONTENT="index,nofollow">
   
   <LINK REL="Previous"  HREF="018248.html">
   <LINK REL="Next"  HREF="018276.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[Mono-list] unicode trouble
   </H1>
    <B>Jonathan Pryor
    </B> 
    <A HREF="mailto:jonpryor%40vt.edu"
       TITLE="[Mono-list] unicode trouble">jonpryor@vt.edu
       </A><BR>
    <I>Mon, 09 Feb 2004 07:16:52 -0500</I>
    <P><UL>
        <LI> Previous message: <A HREF="018248.html">[Mono-list] unicode trouble
</A></li>
        <LI> Next message: <A HREF="018276.html">[Mono-list] unicode trouble
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#18256">[ date ]</a>
              <a href="thread.html#18256">[ thread ]</a>
              <a href="subject.html#18256">[ subject ]</a>
              <a href="author.html#18256">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>On Mon, 2004-02-09 at 02:22, gabor wrote:
&lt;snip/&gt;
&gt;<i> i just can't understand why the designers of dotnet didn't look at the unicode
</I>&gt;<i> standards. i can understand that java has this problem, but java is much older 
</I>&gt;<i> than dotnet.
</I>&gt;<i> 
</I>&gt;<i> maybe it's because winapi uses 16-bit characters?
</I>
I imagine it's due to a memory trade-off.  The easiest way for the
programmer do deal with things would be to just use UCS-32 for all
Unicode strings.  You wouldn't have to worry about code pairs or
anything else like that.

It would also mean that all strings would require 32-bits for each
character, which would eat up *lots* of memory for all strings.  The
most common code points -- US, Europe, Asia -- all easily fit within
16-bits, *by design*.  So the designers had a choice: use 32-bit
characters internally everywhere, forcing nearly all users to &quot;waste&quot;
16-24 bits/character, or 1/2 - 3/4 of all memory dedicated to strings,
or use 16-bit characters internally, which would suite the needs of most
current users (probably &gt; 80%), while only &quot;wasting&quot; 8-bits/character
for the US and parts of Europe, a minority of the world population.

16-bit characters were considered to be a decent trade-off, I would
assume.

An alternative approach could have been for the string to do on-the-fly
conversion between Unicode UCS-32 code-points and an internal
representation, such as UTF-16.  This would imply that System.Char is a
32-bit structure, and that System.String wouldn't conceptually store a
char[] array, but rather some implementation-defined encoding of the
char[] array, to save memory.  This could be argued to complicate
things, but I don't know why else this strategy wouldn't work.

 - Jon



</PRE>
<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI> Previous message: <A HREF="018248.html">[Mono-list] unicode trouble
</A></li>
	<LI> Next message: <A HREF="018276.html">[Mono-list] unicode trouble
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#18256">[ date ]</a>
              <a href="thread.html#18256">[ thread ]</a>
              <a href="subject.html#18256">[ subject ]</a>
              <a href="author.html#18256">[ author ]</a>
         </LI>
       </UL>
</body></html>
