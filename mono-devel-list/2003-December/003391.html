<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2//EN">
<HTML>
 <HEAD>
   <TITLE> [Mono-devel-list] JIT profiling/benchmarking
   </TITLE>
   <LINK REL="Index" HREF="index.html" >
   <LINK REL="made" HREF="mailto:mono-devel-list%40lists.ximian.com?Subject=%5BMono-devel-list%5D%20JIT%20profiling/benchmarking&In-Reply-To=1072759013.3ff100e53a82e%40webmail.mit.edu">
   <META NAME="robots" CONTENT="index,nofollow">
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="003394.html">
   <LINK REL="Next"  HREF="003392.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[Mono-devel-list] JIT profiling/benchmarking</H1>
    <B>Paolo Molaro</B> 
    <A HREF="mailto:mono-devel-list%40lists.ximian.com?Subject=%5BMono-devel-list%5D%20JIT%20profiling/benchmarking&In-Reply-To=1072759013.3ff100e53a82e%40webmail.mit.edu"
       TITLE="[Mono-devel-list] JIT profiling/benchmarking">lupus at ximian.com
       </A><BR>
    <I>Tue Dec 30 06:29:50 EST 2003</I>
    <P><UL>
        <LI>Previous message: <A HREF="003394.html">[Mono-devel-list] running nunit-console?
</A></li>
        <LI>Next message: <A HREF="003392.html">[Mono-devel-list] Hi All!! XSD + XML Doubt
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#3391">[ date ]</a>
              <a href="thread.html#3391">[ thread ]</a>
              <a href="subject.html#3391">[ subject ]</a>
              <a href="author.html#3391">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>On 12/29/03 <A HREF="http://lists.ximian.com/mailman/listinfo/mono-devel-list">ppham at mit.edu</A> wrote:
&gt;<i> I am interested in profiling/benchmarking the JIT compiler in the Mono runtime
</I>&gt;<i> to see how long JITting takes as a function of method length (in IL 
</I>&gt;<i> instructions). My objective is to find (roughly) the break-even point where
</I>&gt;<i> pure interpretation and JIT compilation are equally fast.
</I>
The method length can't be the only variable, you also need to take into
account the number of times a method is executed. Also, any such
measurement is greatly influenced by how much the operations in the
method are optimized in the interp or in the jit, so you have to
define what kind of operations you're insterested in measuring or the
number won't have much meaning.

&gt;<i> My benchmark program includes several methods of varying length, which generate
</I>&gt;<i> from 2000 IL instructions to about 20,000, and I am measuring times (crudely)
</I>
Is your benchmark supposed to have any meaning for real world programs?
You can use the monograph program to get some statistics from commonly
used programs and assemblies: it turns out that in the few assemblies
I have here, the average method length is less than 100 bytes, with some
peak at about 4000 (25k in mcs, because of the huge parse method).

&gt;<i> using System.DateTime.Now.Milliseconds within the program. Each method is
</I>
You should have find out that using Environment.TickCount is way faster
to execute than DateTime.Now.Milliseconds and hence has a much lower
impact on measurement errors.

&gt;<i> It was my assumption that the first time a method is run, it is JIT compiled and 
</I>&gt;<i> cached, and for every call after that the cached/compiled version is run.
</I>&gt;<i> However, that seems not to be the case as I cannot measure any significant
</I>&gt;<i> difference between the first time a method is run and every subsequent time.
</I>
Currently when you create a delegate the delegated method is compiled
right away, so when you execute it, it's already compiled.

&gt;<i> Also, mint, the Mono interpreter, appears to run these methods faster than
</I>&gt;<i> mono, which has JIT by default. I am further puzzled by mint's profiling
</I>
How much faster are we talking here? How much time does the method take
to execute? Are the differences consistent? Without more info it's hard
to tell. From the looks of your test cases, you're just testing the
Decimal implementation that is mostly implemented in C code, so neither
the jit nor the interp are likely going to significantly change the
performance numbers. Also note that correctness may have it's costs and
much more effort has been put into getting the jit to work correctly in
many cases, so the interp may give lower numbers just because it doesn't
bother to do a number of checks or deal with some special cases (the
mono interp is not and should not be considered a CLR engine as far as
I'm concerned: it's more of a porting aid for the rest of mono).

&gt;<i> output which includes statistics such as &quot;Time spent in compilation&quot; and
</I>&gt;<i> &quot;Slowest method to compile&quot;, which shouldn't be in an interpreted CLR at all.
</I>
IL code is not suitable for direct iterpretation, so the interp needs to
do a prepass on the code and we use that time as 'compilation time'.

&gt;<i> If someone could explain how to better benchmark JIT times in Mono, or even
</I>&gt;<i> in .NET on Windows for comparison, I would greatly appreciate it.
</I>&gt;<i> Snippets of my benchmarking program are below.
</I>
*) measure on the actual runtime if Environment.TickCount or
DateTime.Now is faster: use the fastest of the two (or use other ways,
too, like pinvoking into gettimeofday() etc).
*) make sure you _can_ measure something with the instrument you have
(jit times are usually very small, so it's hard to measure them in the
context of an app executing a method, since you can do it only once
anyway). You need to repeat a compilation many times with something
like:
	time ./mono --ncompile 10000 --compile Test:method_name test.exe
Or you may want to change the source and add your own timing
measurements so that startup time is not taken into account.
*) make sure you're really measuring the things you want to measure
(like, the time it takes to execute or jit DateTime.Now...). Also, if you want
to measure the jit times and the time taken to execute some code, you
better choose code that is actually jitted and not code that is
implemented as internal calls (C code compiled by your C compiler for
both execution engines). You also probably want to take the lower
number of a few (&gt;5) runs instead of the average.
Unless you're measuring the exception handling code, benchmarks should
not throw exceptions.
*) measure something that has relevance to the real world:-)
*) use mono -O=all to enable all the currently implemented
optimizations. Play with different optimization options to see how they
affect compile and run times.
*) if you want to use constants for the loop counts, use:
	const int LOOPCOUNT = 100;
instead of
	readonly static int LOOPCOUNT = 100;

lupus

-- 
-----------------------------------------------------------------
<A HREF="http://lists.ximian.com/mailman/listinfo/mono-devel-list">lupus at debian.org</A>                                     debian/rules
<A HREF="http://lists.ximian.com/mailman/listinfo/mono-devel-list">lupus at ximian.com</A>                             Monkeys do it better

</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="003394.html">[Mono-devel-list] running nunit-console?
</A></li>
	<LI>Next message: <A HREF="003392.html">[Mono-devel-list] Hi All!! XSD + XML Doubt
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#3391">[ date ]</a>
              <a href="thread.html#3391">[ thread ]</a>
              <a href="subject.html#3391">[ subject ]</a>
              <a href="author.html#3391">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="http://lists.ximian.com/mailman/listinfo/mono-devel-list">More information about the Mono-devel-list
mailing list</a><br>
</body></html>
